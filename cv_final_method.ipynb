{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import corpus as corpus_class\n",
    "import categories, filters\n",
    "from filters import std_filters\n",
    "from sklearn.metrics import f1_score\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from transform import TrainingSupport\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics.classification import UndefinedMetricWarning\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", np.VisibleDeprecationWarning)\n",
    "warnings.simplefilter(\"ignore\", UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = corpus_class.load_from_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qfile_train = 'question_train.csv'\n",
    "qcatfile_train = 'question_category_train.csv'\n",
    "catfile = 'category.csv'\n",
    "qfile_test = 'question_test.csv'\n",
    "filtees = std_filters()\n",
    "\n",
    "corpus = corpus_class.corpus( categories.categories(subcategories=False) );\n",
    "corpus.load(qfile_train, qcatfile_train);\n",
    "corpus.process(corpus_size=1, test_corpus=False, **filtees);\n",
    "corpus.save();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "\n",
    "def save_results(cv_results, clf_name):\n",
    "    f_name = \"cv_final/\" + clf_name\n",
    "    f_name += time.strftime(\"_%Y-%m-%d_%H-%M\", time.gmtime())\n",
    "    f_name += \".pkl\"\n",
    "    with open(f_name, 'wb') as file:\n",
    "        pickle.dump(cv_results, file)\n",
    "    return f_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_selection import SelectPercentile, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MNB = Pipeline(steps=[\n",
    "        ('tr_supp', TrainingSupport()),\n",
    "        ('tfidf', None),\n",
    "        ('selection', SelectPercentile(score_func=chi2)),\n",
    "        ('mnb', MultinomialNB())\n",
    "    ])\n",
    "\n",
    "ALPHA = np.logspace(-3,2,30,base=10)\n",
    "PERCENTILE = np.linspace(50,100,6)\n",
    "TFIF = []\n",
    "\n",
    "NB_PARAMS = [\n",
    "    {\n",
    "        'tfidf': [TfidfTransformer()],\n",
    "        'tfidf__use_idf': [True, False],\n",
    "        'selection__percentile': PERCENTILE,\n",
    "        'mnb__alpha': ALPHA,\n",
    "        'mnb__fit_prior': [True, False]\n",
    "    },\n",
    "    {\n",
    "        'tfidf': [None],\n",
    "        'selection__percentile': PERCENTILE,\n",
    "        'mnb__alpha': ALPHA,\n",
    "        'mnb__fit_prior': [True, False]\n",
    "    }\n",
    "]\n",
    "\n",
    "NB_CV = GridSearchCV(MNB, NB_PARAMS, scoring='f1_macro',\n",
    "                     fit_params=None, n_jobs=-1, iid=False, refit=True,\n",
    "                     cv=4, verbose=0, pre_dispatch='2*n_jobs', error_score='raise',\n",
    "                     return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NB_CV.fit(corpus.X_all, corpus.y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cv_final/MNB_2017-02-12_10-52.pkl'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_results(NB_CV, \"MNB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tr_supp', <transform.TrainingSupport at 0x7f4076c97710>),\n",
       " ('tfidf',\n",
       "  TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
       " ('selection', SelectPercentile(percentile=100.0,\n",
       "           score_func=<function chi2 at 0x7f4079c3d730>)),\n",
       " ('mnb',\n",
       "  MultinomialNB(alpha=0.1743328822199989, class_prior=None, fit_prior=False))]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_CV.best_estimator_.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.612481857765\n"
     ]
    }
   ],
   "source": [
    "corpus.FREEZE_RANDOM = False\n",
    "corpus.simple_split(0.1);\n",
    "NB_CV.best_estimator_.fit(corpus.X_tr, corpus.y_tr)\n",
    "print( NB_CV.best_estimator_.score(corpus.X_te, corpus.y_te) )\n",
    "corpus.simple_split(0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_selection import SelectPercentile, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LR = Pipeline(steps=[\n",
    "        ('tr_supp', TrainingSupport()),\n",
    "        ('tfidf', None),\n",
    "        ('selection', SelectPercentile(score_func=chi2)),\n",
    "        ('lr', LogisticRegression(penalty='l1'))\n",
    "    ])\n",
    "\n",
    "C = np.logspace(-3,2,50,base=10)\n",
    "PERCENTILE = np.linspace(50,100,6)\n",
    "\n",
    "LR_PARAMS = [\n",
    "    {\n",
    "        'tfidf': [TfidfTransformer()],\n",
    "        'tfidf__use_idf': [True, False],\n",
    "        'selection__percentile': PERCENTILE,\n",
    "        'lr__C': C\n",
    "    },\n",
    "    {\n",
    "        'tfidf': [None],\n",
    "        'selection__percentile': PERCENTILE,\n",
    "        'lr__C': C\n",
    "    }\n",
    "]\n",
    "\n",
    "LR_CV = GridSearchCV(LR, LR_PARAMS, scoring='f1_macro',\n",
    "                     fit_params=None, n_jobs=-1, iid=False, refit=True,\n",
    "                     cv=4, verbose=0, pre_dispatch='2*n_jobs', error_score='raise',\n",
    "                     return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LR_CV.fit(corpus.X_all, corpus.y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tr_supp', <transform.TrainingSupport at 0x7f4078404208>),\n",
       " ('tfidf', TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False,\n",
       "           use_idf=False)),\n",
       " ('selection', SelectPercentile(percentile=100.0,\n",
       "           score_func=<function chi2 at 0x7f4079c3d730>)),\n",
       " ('lr', LogisticRegression(C=3.7275937203149416, class_weight=None, dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False))]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_results(LR_CV, \"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.604499274311\n"
     ]
    }
   ],
   "source": [
    "(X_tr, y_tr), (X_te, y_te) = corpus.simple_split(0.1);\n",
    "LR_CV.best_estimator_.fit(X_tr, y_tr)\n",
    "print( LR_CV.best_estimator_.score(X_te, y_te) )\n",
    "corpus.simple_split(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tr_supp', <transform.TrainingSupport at 0x7f4078404208>),\n",
       " ('tfidf', TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False,\n",
       "           use_idf=False)),\n",
       " ('selection', SelectPercentile(percentile=100.0,\n",
       "           score_func=<function chi2 at 0x7f4079c3d730>)),\n",
       " ('lr', LogisticRegression(C=3.7275937203149416, class_weight=None, dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False))]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_CV.best_estimator_.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Supported Vector Maschines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_selection import SelectPercentile, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LinearSVM = Pipeline(steps=[\n",
    "        ('tr_supp', TrainingSupport()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('selection', SelectPercentile(score_func=chi2)),\n",
    "        ('lsvm', LinearSVC())\n",
    "    ])\n",
    "\n",
    "PERCENTILE = np.linspace(50,100,6)\n",
    "C = np.logspace(-2,2,31,base=10)\n",
    "INTERCEPT_SCALING = np.logspace(0,3,11,base=10)\n",
    "\n",
    "LSVM_PARAMS = [\n",
    "    {\n",
    "        'selection__percentile': PERCENTILE,\n",
    "        'lsvm__C': C,\n",
    "        'lsvm__intercept_scaling': [1],\n",
    "        'lsvm__class_weight': [None]\n",
    "    },\n",
    "    {\n",
    "        'selection__percentile': PERCENTILE,\n",
    "        'lsvm__C': C,\n",
    "        'lsvm__intercept_scaling': INTERCEPT_SCALING,\n",
    "        'lsvm__class_weight': ['balanced']\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LSVM_CV = GridSearchCV(LinearSVM, LSVM_PARAMS_ZOOM2, scoring='f1_macro',\n",
    "                     fit_params=None, n_jobs=-1, iid=False, refit=True,\n",
    "                     cv=3, verbose=0, pre_dispatch='2*n_jobs', error_score='raise',\n",
    "                     return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LSVN_CV.fit(corpus.X_all, corpus.y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_results(LSVN_CV, \"LSVM\")\n",
    "LSVN_CV.best_estimator_.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LSVM_CV_ZOOM2.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"cv_final/LSVM_CV_ZOOM2\", 'rb') as file:\n",
    "    LSVM_CV = pickle.load(file)\n",
    "    df = pd.DataFrame( LSVM_CV.cv_results_ ).sort_values(\"mean_test_score\", ascending=False)\n",
    "with open(\"cv_final/LSVM_CV_ZOOM2.html\", \"w+\") as file:\n",
    "    file.write( df.to_html(columns=[\"mean_test_score\",\n",
    "                                    \"mean_fit_time\",\n",
    "                                    \"param_lsvm__C\",\n",
    "                                    'param_lsvm__intercept_scaling',\n",
    "                                    'param_lsvm__class_weight',\n",
    "                                    'param_selection__percentile']\n",
    "                          ) \n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus.simple_split(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lsvm = LSVM_CV.best_estimator_\n",
    "lsvm.fit(corpus.X_tr, corpus.y_tr)\n",
    "f1_score(lsvm.predict(corpus.X_te), corpus.y_te, average=\"macro\"), lsvm.score(corpus.X_te, corpus.y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = df.loc[60]['params']\n",
    "lsvm2 = LinearSVM.set_params(**params)\n",
    "lsvm2.fit(corpus.X_tr, corpus.y_tr)\n",
    "f1_score(lsvm2.predict(corpus.X_te), corpus.y_te, average=\"macro\"), lsvm2.score(corpus.X_te, corpus.y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"cv_final/MNB_2017-02-12_10-52.pkl\", 'rb') as file:\n",
    "    NB_CV = pickle.load(file)\n",
    "    df = pd.DataFrame( NB_CV.cv_results_ ).sort_values(\"mean_test_score\", ascending=False)\n",
    "with open(\"cv_final/NB_HTML.html\", \"w+\") as file:\n",
    "    file.write( df.to_html(columns=[\"mean_test_score\",\n",
    "                                    \"param_mnb__alpha\",\n",
    "                                    'param_mnb__fit_prior',\n",
    "                                    'param_selection__percentile',\n",
    "                                    'param_tfidf',\n",
    "                                    'param_tfidf__use_idf'\n",
    "                                   ]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = \"LR_2017-02-12_11-44\"\n",
    "with open(\"cv_final/\"+filename+\".pkl\", 'rb') as file:\n",
    "    CV = pickle.load(file)\n",
    "    df = pd.DataFrame( CV.cv_results_ ).sort_values(\"mean_test_score\", ascending=False)\n",
    "\n",
    "with open(\"cv_final/html/\"+filename+\".html\", \"w+\") as file:\n",
    "    file.write( df.to_html(columns=[\"mean_fit_time\",\n",
    "                                    \"mean_test_score\",\n",
    "                                    \"param_lr__C\",\n",
    "                                    'param_selection__percentile',\n",
    "                                    'param_tfidf',\n",
    "                                    'param_tfidf__use_idf'\n",
    "                                   ]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'mean_score_time', 'mean_test_score',\n",
       "       'mean_train_score', 'param_lr__C', 'param_selection__percentile',\n",
       "       'param_tfidf', 'param_tfidf__use_idf', 'params', 'rank_test_score',\n",
       "       'split0_test_score', 'split0_train_score', 'split1_test_score',\n",
       "       'split1_train_score', 'split2_test_score', 'split2_train_score',\n",
       "       'split3_test_score', 'split3_train_score', 'std_fit_time',\n",
       "       'std_score_time', 'std_test_score', 'std_train_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Classfiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Bayes MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MNB = Pipeline(steps=[\n",
    "        ('tr_supp', TrainingSupport()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('selection', SelectPercentile(score_func=chi2)),\n",
    "        ('mnb', MultinomialNB())\n",
    "    ])\n",
    "\n",
    "MNB.set_params(**{\n",
    "        \"mnb__alpha\": 0.174333,\n",
    "        \"mnb__fit_prior\": False,\n",
    "        \"selection__percentile\": 100\n",
    "    })\n",
    "\n",
    "with open(\"best_estimators/MultinomialNB.pkl\", \"wb+\") as file:\n",
    "    pickle.dump(MNB, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LR = Pipeline(steps=[\n",
    "        ('tr_supp', TrainingSupport()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('selection', SelectPercentile(score_func=chi2)),\n",
    "        ('lr', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "LR.set_params(**{\n",
    "        \"tfidf__use_idf\": False,\n",
    "        \"selection__percentile\": 100,\n",
    "        \"lr__penalty\": 'l1',\n",
    "        \"lr__C\": 2.94705\n",
    "    })\n",
    "\n",
    "with open(\"best_estimators/LogisticRegression.pkl\", \"wb+\") as file:\n",
    "    pickle.dump(LR, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Supported Vector Machine LSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from transform import LinearSVC\n",
    "\n",
    "LinearSVM = Pipeline(steps=[\n",
    "        ('tr_supp', TrainingSupport()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('selection', SelectPercentile(score_func=chi2)),\n",
    "        ('lsvm', LinearSVC())\n",
    "    ])\n",
    "\n",
    "LinearSVM.set_params(**{\n",
    "        \"lsvm__class_weight\": None,\n",
    "        \"lsvm__intercept_scaling\": 1.0,\n",
    "        \"lsvm__C\": 0.615848,\n",
    "        \"selection__percentile\": 70\n",
    "    })\n",
    "\n",
    "with open(\"best_estimators/LinearSVM.pkl\", \"wb+\") as file:\n",
    "    pickle.dump(LinearSVM, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
