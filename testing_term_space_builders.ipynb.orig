{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv, importlib\n",
    "import categories\n",
    "import corpus as corpus_class\n",
    "import filters, vocabulary_builders, vocabulary_tester\n",
    "from vocabulary_builders import most_common, most_common_reduced, ig_based, ig_based_non_uniform, xi_square_based\n",
    "from vocabulary_builders import cc_based, cc_based_overall, xi_square_based_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cats = categories.categories()\n",
    "corpus = corpus_class.corpus(cats)\n",
    "corpus.load(\"question_train.csv\", \"question_category_train.csv\")\n",
    "sentence_filters = [filters.punctuation_filter]\n",
    "word_filters = [filters.small_word_filter, filters.stopword_filter, filters.stemming_filter]\n",
    "corpus.process(sentence_filters, word_filters, tr_set_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pickle\n",
    "corpus_file = open(\"corpus.pkl\", \"wb+\")\n",
    "pickle.dump(corpus,corpus_file)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
=======
   "execution_count": 13,
>>>>>>> f61897951743fa56337b76544eab85447b9890b8
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
<<<<<<< HEAD
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
=======
     "ename": "ImportError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c8d0f9b72dc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"categoryids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'sklearn'"
     ]
>>>>>>> f61897951743fa56337b76544eab85447b9890b8
    }
   ],
   "source": [
    "import numpy as np\n",
    "f = np.load(\"features.npz\")\n",
    "X = f['features']; y = f[\"categoryids\"]\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
<<<<<<< HEAD
    "clf.fit(X[:,:10000].T, y[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.   6.   1.  10.   4.   8.   1.   4.   5.   6.]\n",
      "[  8.   6.   1.  10.   4.   6.   7.   4.   5.   6.]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict(X[:,-10:].T))\n",
    "print(y[-10:])"
=======
    "clf.fit(X[:1000], y[:1000])"
>>>>>>> f61897951743fa56337b76544eab85447b9890b8
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cc-based vocabulary builder, arguments {'M': 1}, \n",
      " --- vocabulary volume:  14\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.30609010640706363\n",
      " --- uniform accuracy: 0.16956150534120212\n",
      "\n",
      "cc-based vocabulary builder, arguments {'read_from_file': True, 'M': 50}, \n",
      " --- vocabulary volume:  700\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.47249264206474983\n",
      " --- uniform accuracy: 0.34222069589805343\n",
      "\n",
      "cc-based vocabulary builder, arguments {'read_from_file': True, 'M': 100}, \n",
      " --- vocabulary volume:  1400\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.48947249264206477\n",
      " --- uniform accuracy: 0.3438419834544794\n",
      "\n",
      "cc-based vocabulary builder, arguments {'read_from_file': True, 'M': 200}, \n",
      " --- vocabulary volume:  2800\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.4808693683495585\n",
      " --- uniform accuracy: 0.31739551350622114\n",
      "\n",
      "cc-based vocabulary builder, arguments {'read_from_file': True, 'M': 300}, \n",
      " --- vocabulary volume:  4090\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.46570070183382384\n",
      " --- uniform accuracy: 0.2903853336189847\n",
      "\n",
      "cc-based vocabulary builder, arguments {'read_from_file': True, 'M': 400}, \n",
      " --- vocabulary volume:  5172\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.45438080144894727\n",
      " --- uniform accuracy: 0.2740252432898895\n",
      "\n",
      "cc-based vocabulary builder, arguments {'read_from_file': True, 'M': 500}, \n",
      " --- vocabulary volume:  6234\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.45075843332578674\n",
      " --- uniform accuracy: 0.26670155199572576\n",
      "\n",
      "cc-based vocabulary builder, arguments {'read_from_file': True, 'M': 600}, \n",
      " --- vocabulary volume:  7158\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.43966493094860765\n",
      " --- uniform accuracy: 0.25409479331458\n",
      "\n",
      "\n",
      " test are all finshed and saved into file!\n"
     ]
    }
   ],
   "source": [
    "args = [(\"\", {\"M\": 1})]\n",
    "for M in [50, 100, 200, 300, 400, 500, 600]:\n",
    "    args += (\"\", {\"M\": M, \"read_from_file\": True}),\n",
    "\n",
    "vocabulary_tester.test(\"cc-based\", cc_based, args, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xi-square vocabulary builder, arguments {'read_from_file': True, 'M': 1}, \n",
      " --- vocabulary volume:  1\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.26760244509848313\n",
      " --- uniform accuracy: 0.12375646206987148\n",
      "\n",
      "xi-square vocabulary builder, arguments {'read_from_file': True, 'M': 50}, \n",
      " --- vocabulary volume:  69\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.410459587955626\n",
      " --- uniform accuracy: 0.27620131517685953\n",
      "\n",
      "xi-square vocabulary builder, arguments {'read_from_file': True, 'M': 100}, \n",
      " --- vocabulary volume:  140\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.4609463436721757\n",
      " --- uniform accuracy: 0.33095694335773324\n",
      "\n",
      "xi-square vocabulary builder, arguments {'read_from_file': True, 'M': 200}, \n",
      " --- vocabulary volume:  298\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5028299750962192\n",
      " --- uniform accuracy: 0.3914201242889512\n",
      "\n",
      "xi-square vocabulary builder, arguments {'read_from_file': True, 'M': 300}, \n",
      " --- vocabulary volume:  459\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5175458455965587\n",
      " --- uniform accuracy: 0.40808221185632537\n",
      "\n",
      "xi-square vocabulary builder, arguments {'read_from_file': True, 'M': 400}, \n",
      " --- vocabulary volume:  596\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5272809599275526\n",
      " --- uniform accuracy: 0.4140960483575436\n",
      "\n",
      "xi-square vocabulary builder, arguments {'read_from_file': True, 'M': 500}, \n",
      " --- vocabulary volume:  734\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5313561240661082\n",
      " --- uniform accuracy: 0.42237776637277086\n",
      "\n",
      "xi-square vocabulary builder, arguments {'read_from_file': True, 'M': 600}, \n",
      " --- vocabulary volume:  871\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5426760244509848\n",
      " --- uniform accuracy: 0.4349874708194498\n",
      "\n",
      "xi-square vocabulary builder, arguments {'read_from_file': True, 'M': 1000}, \n",
      " --- vocabulary volume:  1401\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5587502829975096\n",
      " --- uniform accuracy: 0.4436686458388105\n",
      "\n",
      "xi-square vocabulary builder, arguments {'read_from_file': True, 'M': 2500}, \n",
      " --- vocabulary volume:  3630\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5573918949513245\n",
      " --- uniform accuracy: 0.4106264949890605\n",
      "\n",
      "xi-square vocabulary builder, arguments {'read_from_file': True, 'M': 3000}, \n",
      " --- vocabulary volume:  4328\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.554222322843559\n",
      " --- uniform accuracy: 0.40292792380160186\n",
      "\n",
      "xi-square vocabulary builder, arguments {'read_from_file': True, 'M': 4000}, \n",
      " --- vocabulary volume:  6668\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5252433778582748\n",
      " --- uniform accuracy: 0.3501225532518162\n",
      "\n",
      "xi-square vocabulary builder, arguments {'read_from_file': True, 'M': 5000}, \n",
      " --- vocabulary volume:  8048\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5118858954041204\n",
      " --- uniform accuracy: 0.32742214304872036\n",
      "\n",
      "\n",
      " test are all finshed and saved into file!\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(vocabulary_builders)\n",
    "args = []\n",
    "for M in [1, 50, 100, 200, 300, 400, 500, 600, 1000, 2500, 3000, 4000, 5000]:\n",
    "    args += [(\"\", {\"M\": M, \"read_from_file\": True})]\n",
    "\n",
    "vocabulary_tester.test(\"xi-square\", vocabulary_builders.xi_square_based, args, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cc-based overall vocabulary builder, arguments {'read_from_file': True, 'M': 1}, \n",
      " --- vocabulary volume:  1\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.2626216889291374\n",
      " --- uniform accuracy: 0.12452472345484078\n",
      "\n",
      "cc-based overall vocabulary builder, arguments {'read_from_file': True, 'M': 250}, \n",
      " --- vocabulary volume:  250\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.4034412497170025\n",
      " --- uniform accuracy: 0.2792811527401758\n",
      "\n",
      "cc-based overall vocabulary builder, arguments {'read_from_file': True, 'M': 500}, \n",
      " --- vocabulary volume:  500\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.40117726964002715\n",
      " --- uniform accuracy: 0.2691361519717416\n",
      "\n",
      "\n",
      " test are all finshed and saved into file!\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(vocabulary_builders)\n",
    "args = [(\"\", {\"M\": 1, \"read_from_file\": True})]\n",
    "for M in [250, 500, 750, 1000, 1250, 1500, 2000, 2500, 3000, 4000, 6000]:\n",
    "    args += (\"\", {\"M\": M, \"read_from_file\": True}),\n",
    "\n",
    "vocabulary_tester.test(\"cc-based overall\", vocabulary_builders.cc_based_overall, args, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xi-square-based overall vocabulary builder, arguments {'read_from_file': True, 'M': 1}, \n",
      " --- vocabulary volume:  1\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.2626216889291374\n",
      " --- uniform accuracy: 0.12452472345484078\n",
      "\n",
      "xi-square-based overall vocabulary builder, arguments {'read_from_file': True, 'M': 250}, \n",
      " --- vocabulary volume:  377\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5123386914195155\n",
      " --- uniform accuracy: 0.39843033557367596\n",
      "\n",
      "xi-square-based overall vocabulary builder, arguments {'read_from_file': True, 'M': 500}, \n",
      " --- vocabulary volume:  739\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5336201041430836\n",
      " --- uniform accuracy: 0.4207501493645115\n",
      "\n",
      "\n",
      " test are all finshed and saved into file!\n"
     ]
    }
   ],
   "source": [
    "args = [(\"\", {\"M\": 1,\"read_from_file\": True})]\n",
    "for M in [250, 500, 750, 1000, 1250, 1500, 2000, 2500, 3000, 4000, 6000]:\n",
    "    args += (\"\", {\"M\": M, \"read_from_file\": True}),\n",
    "\n",
    "vocabulary_tester.test(\"xi-square-based overall\", vocabulary_builders.xi_square_based_overall, args, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = \"vacabulary_test_results/evaluation_all\"\n",
    "file_name += time.strftime(\"_%d-%m-%Y_%H-%M.csv\", time.gmtime())\n",
    "res_file = open(file_name, 'w+')\n",
    "res_writer = csv.writer(res_file)\n",
    "res_writer.writerow([\"vocabulary_builder\", \"comment\", \"arguments\",\n",
    "                     \"vocabulary_length\", \"tr_set_size\", \"te_set_size\", \"standard_accuracy\", \"uniform_accuracy\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xi-square vocabulary builder, arguments {'M': 1}, \n",
      " --- vocabulary volume:  1\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.2730359972832239\n",
      " --- uniform accuracy: 0.12481316713749645\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 50, 'read_from_file': True}, \n",
      " --- vocabulary volume:  71\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.4337785827484718\n",
      " --- uniform accuracy: 0.2900272582719106\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 100, 'read_from_file': True}, \n",
      " --- vocabulary volume:  144\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.4788317862802807\n",
      " --- uniform accuracy: 0.342110473280293\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 200, 'read_from_file': True}, \n",
      " --- vocabulary volume:  295\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5166402535657686\n",
      " --- uniform accuracy: 0.3918767839722415\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 300, 'read_from_file': True}, \n",
      " --- vocabulary volume:  452\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5327145121122934\n",
      " --- uniform accuracy: 0.4088423215991009\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 400, 'read_from_file': True}, \n",
      " --- vocabulary volume:  608\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.54403441249717\n",
      " --- uniform accuracy: 0.426656586373065\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 500, 'read_from_file': True}, \n",
      " --- vocabulary volume:  748\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5582974869821146\n",
      " --- uniform accuracy: 0.4402356799933854\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 600, 'read_from_file': True}, \n",
      " --- vocabulary volume:  889\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5594294770206022\n",
      " --- uniform accuracy: 0.4393819898515549\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 1000, 'read_from_file': True}, \n",
      " --- vocabulary volume:  1404\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5693909893592937\n",
      " --- uniform accuracy: 0.4428090594968383\n",
      "\n",
      "\n",
      " test are all finshed and saved into file!\n"
     ]
    }
   ],
   "source": [
    "args = [(\"\", {\"M\": 1})]\n",
    "for M in [50, 100, 200, 300, 400, 500, 600, 1000]:\n",
    "    args += (\"\", {\"M\": M, \"read_from_file\": True}),\n",
    "\n",
    "vocabulary_tester.test(\"xi-square\", xi_square_based, args, corpus, csv_file_writer=res_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xi-square vocabulary builder, arguments {'M': 1500, 'read_from_file': True}, \n",
      " --- vocabulary volume:  2116\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5745981435363369\n",
      " --- uniform accuracy: 0.43670034594487567\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 1800, 'read_from_file': True}, \n",
      " --- vocabulary volume:  2479\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5773149196287073\n",
      " --- uniform accuracy: 0.436832576775667\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 2200, 'read_from_file': True}, \n",
      " --- vocabulary volume:  3007\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.57889970568259\n",
      " --- uniform accuracy: 0.4324285745373647\n",
      "\n",
      "\n",
      " test are all finshed and saved into file!\n"
     ]
    }
   ],
   "source": [
    "args = []\n",
    "for M in [1500,1800,2200]:\n",
    "    args += (\"\", {\"M\": M, \"read_from_file\": True}),\n",
    "\n",
    "vocabulary_tester.test(\"xi-square\", xi_square_based, args, corpus, csv_file_writer=res_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ig-based vocabulary builder, arguments {'M': 1}, \n",
      " --- vocabulary volume:  9\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.32669232510753904\n",
      " --- uniform accuracy: 0.1876940472661592\n",
      "\n",
      "ig-based vocabulary builder, arguments {'M': 50, 'read_from_file': True}, \n",
      " --- vocabulary volume:  465\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5460719945664478\n",
      " --- uniform accuracy: 0.44149340171883245\n",
      "\n",
      "ig-based vocabulary builder, arguments {'M': 100, 'read_from_file': True}, \n",
      " --- vocabulary volume:  951\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5625990491283677\n",
      " --- uniform accuracy: 0.44632776436915556\n",
      "\n",
      "ig-based vocabulary builder, arguments {'M': 200, 'read_from_file': True}, \n",
      " --- vocabulary volume:  1989\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.575956531582522\n",
      " --- uniform accuracy: 0.4402253628568487\n",
      "\n",
      "ig-based vocabulary builder, arguments {'M': 300, 'read_from_file': True}, \n",
      " --- vocabulary volume:  2973\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5671270092823183\n",
      " --- uniform accuracy: 0.4153295142277682\n",
      "\n",
      "ig-based vocabulary builder, arguments {'M': 400, 'read_from_file': True}, \n",
      " --- vocabulary volume:  3942\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5399592483586144\n",
      " --- uniform accuracy: 0.36173633249845805\n",
      "\n",
      "ig-based vocabulary builder, arguments {'M': 1000, 'read_from_file': True}, \n",
      " --- vocabulary volume:  8244\n",
      " --- training classifier...\n"
     ]
    }
   ],
   "source": [
    "args = [(\"\", {\"M\": 1})]\n",
    "for M in [50, 100, 200, 300, 400, 500, 600, 1000]:\n",
    "    args += (\"\", {\"M\": M, \"read_from_file\": True})\n",
    "\n",
    "vocabulary_tester.test(\"ig-based\", ig_based, args, corpus, csv_file_writer=res_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "args = [(\"\", {\"M\": 1, \"read_from_file\": True})]\n",
    "for M in [500, 1000, 2000, 3000, 5000, 10000]:\n",
    "    args += (\"\", {\"M\": M, \"read_from_file\": True}),\n",
    "\n",
    "vocabulary_tester.test(\"ig-based non uniform\", ig_based_non_uniform, args, corpus, csv_file_writer=res_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "args = [(\"\", {\"M\": 1})]\n",
    "for M in [1, 50, 100, 200, 300, 400, 500, 600, 1000]: args += (\"\", {\"M\": M})\n",
    "\n",
    "vocabulary_tester.test(\"most-common\", most_common, args, corpus, csv_file_writer=res_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
