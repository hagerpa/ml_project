{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score as f1_scorer\n",
    "import corpus as corpus_class\n",
    "from filters import std_filters\n",
    "import categories\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "corpus = corpus_class.corpus( categories.categories() )\n",
    "corpus.load(\"question_train.csv\", \"question_category_train.csv\")\n",
    "corpus.process(**std_filters(), corpus_size=-1)\n",
    "corpus.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = corpus_class.load_from_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 categories. \n",
      "14417 docuemnts loaded from file. \n",
      "processed: True \n",
      "\t Training-set, Test-set size: None \n",
      "\t\t sentence_filters: ['punctuation_filter'] \n",
      "\t\t word_filters: ['small_word_filter', 'stopword_filter', 'stemming_filter'] \n",
      "made numeric features: False \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time, csv, pickle\n",
    "import itertools as it\n",
    "\n",
    "def CV(corpus, clf_class, clf_name, clf_params, feat_params, n_folds):\n",
    "    file_name = \"cv_results/\" + clf_name\n",
    "    file_name += time.strftime(\"_%Y-%m-%d_%H-%M\", time.gmtime())\n",
    "    header = [\"id\", \"f1\", \"accuracy\", \"time\"] + list(feat_params[0].keys()) + list(clf_params[0].keys())\n",
    "    \n",
    "    csv_file = open(file_name+\".csv\", 'w+')\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(header)\n",
    "    \n",
    "    pkl_file = open(file_name+\".pkl\", 'wb+')\n",
    "    results = {}\n",
    "    \n",
    "    corpus.cv_split(n_folds)\n",
    "    \n",
    "    idx = 0\n",
    "    for c_par, f_par in it.product(clf_params, feat_params):\n",
    "        results[idx] = {}\n",
    "        results[idx]['feat_params'] = f_par\n",
    "        results[idx]['clf_params'] = c_par\n",
    "        \n",
    "        f1_scores, acc_scores, times = [], [], []\n",
    "        \n",
    "        fold = 0\n",
    "        for coprus in corpus:\n",
    "            results[idx][fold] = {}\n",
    "            corpus.make_features(**f_par)\n",
    "            \n",
    "            t = time.time() ### Time measure A ###\n",
    "            \n",
    "            clf = clf_class(**c_par)\n",
    "            clf.fit(corpus.X_tr, corpus.y_tr)\n",
    "            y_pred = clf.predict(corpus.X_te)\n",
    "            \n",
    "            dt = time.time() - t ### Time measure B ###\n",
    "            \n",
    "            acc = clf.score(corpus.X_te, corpus.y_te)\n",
    "            f1 = f1_scorer(corpus.y_te, y_pred, average=\"macro\")\n",
    "            \n",
    "            f1_scores += [ f1 ]\n",
    "            acc_scores += [ acc ]\n",
    "            times += [ dt ]\n",
    "            \n",
    "            results[idx][fold]['acc_score'] = acc\n",
    "            results[idx][fold]['y_pred'] = y_pred\n",
    "            results[idx][fold]['f1_score'] = f1\n",
    "            results[idx][fold]['time'] = dt\n",
    "            \n",
    "            fold += 1\n",
    "\n",
    "        results[idx]['f1_score'] = np.mean(f1_scores)\n",
    "        results[idx]['acc_score'] = np.mean(acc_scores)\n",
    "        results[idx]['time'] = np.mean(times)\n",
    "        \n",
    "        row = [ idx ]\n",
    "        row += [results[idx]['f1_score'], results[idx]['acc_score'], results[idx]['time']]\n",
    "        row += list(f_par.values()) + list(c_par.values())\n",
    "        csv_writer.writerow( row )\n",
    "        print(row)\n",
    "        \n",
    "        corpus.reset()\n",
    "        idx += 1\n",
    "    \n",
    "    pickle.dump(results, pkl_file)\n",
    "    \n",
    "    csv_file.close()\n",
    "    pkl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sklearn.linear_model.logistic.LogisticRegression,\n",
       " 'LogisticRegression',\n",
       " [{'C': 0.5, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 0.70710678118654757, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1.4142135623730951, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 2.0, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 2.8284271247461903, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 4.0, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 5.6568542494923806, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 8.0, 'penalty': 'l1', 'solver': 'liblinear'}],\n",
       " [{'M': -1}])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0.52902782099113732, 0.5865322917191792, 0.53402058283487952, -1, 2.0, 'l1', 'liblinear']\n",
      "[1, 0.53052358916347331, 0.58667116569293631, 3.2402540047963462, -1, 2.5, 'l1', 'liblinear']\n",
      "[2, 0.52836630289326203, 0.58646299164987914, 0.66099397341410315, -1, 3.0, 'l1', 'liblinear']\n",
      "[3, 0.52717926806137394, 0.58590672814301314, 16.885004997253418, -1, 3.5, 'l1', 'liblinear']\n",
      "[4, 0.52684002910051975, 0.58521443522141725, 56.349968592325844, -1, 4.0, 'l1', 'liblinear']\n"
     ]
    }
   ],
   "source": [
    "CV(corpus, *LogisticRegression_params(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id     f1_score        acc_score       M               C               time           \n",
      "1      0.531           0.587           -1              2.5             3.2403         \n",
      "0      0.529           0.587           -1              2.0             0.53402        \n",
      "2      0.528           0.586           -1              3.0             0.66099        \n",
      "3      0.527           0.586           -1              3.5             16.885         \n",
      "4      0.527           0.585           -1              4.0             56.35          \n"
     ]
    }
   ],
   "source": [
    "with open(\"cv_results/\"+\"LogisticRegression_2016-12-25_19-24.pkl\", 'rb') as file:\n",
    "    file.seek(0)\n",
    "    results = pickle.load(file)\n",
    "    \n",
    "    f1_scores = -np.array([results[i][\"f1_score\"] for i in results])\n",
    "    best_idx = f1_scores.argsort()\n",
    "    \n",
    "    print(\"{0:6} {1:15} {2:15} {3:15} {4:15} {5:15}\".format(\"id\", \"f1_score\", \"acc_score\", \"M\", \"C\", \"time\"))\n",
    "    for idx in best_idx:\n",
    "        print(\"{0:<6} {f1_score:<15.3} {acc_score:<15.3} {feat_params[M]:<15} \\\n",
    "{clf_params[C]:<15.3} {time:<15.5}\".format(idx, **results[idx])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MultinomialNB_params():\n",
    "    clf_class = MultinomialNB\n",
    "    clf_name = \"MultinomialNB\"\n",
    "    clf_params = [{\"alpha\":M} for M in np.logspace(-5,1,7)]\n",
    "\n",
    "    M_max = np.log2(len(corpus.all_terms))-1\n",
    "    feat_params = [{\"M\":int(M)} for M in np.logspace(6,M_max,7, base=2)]\n",
    "    feat_params += [{\"M\":-1}]\n",
    "\n",
    "    return clf_class, clf_name, clf_params, feat_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LogisticRegression_params():\n",
    "    clf_class = LogisticRegression\n",
    "    clf_name = \"LogisticRegression\"\n",
    "    #clf_params = [{\"C\":M, \"penalty\": 'l1', \"solver\": 'liblinear'} for M in np.logspace(1,2,4, base=2)]\n",
    "    clf_params = [{\"C\":M, \"penalty\": 'l1', \"solver\": 'liblinear'} for M in np.linspace(2,4,5)]\n",
    "    feat_params = [{\"M\":-1}]\n",
    "    \n",
    "    return clf_class, clf_name, clf_params, feat_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sklearn.linear_model.logistic.LogisticRegression,\n",
       " 'LogisticRegression',\n",
       " [{'C': 2.0, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 2.5, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 3.0, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 3.5, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 4.0, 'penalty': 'l1', 'solver': 'liblinear'}],\n",
       " [{'M': -1}])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
