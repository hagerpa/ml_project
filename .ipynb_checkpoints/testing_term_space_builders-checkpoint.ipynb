{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv, importlib\n",
    "import categories\n",
    "import corpus as corpus_class\n",
    "import filters, vocabulary_builders, vocabulary_tester\n",
    "from vocabulary_builders import most_common, most_common_reduced, ig_based, ig_based_non_uniform, xi_square_based\n",
    "from vocabulary_builders import cc_based, cc_based_overall, xi_square_based_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cats = categories.categories()\n",
    "corpus = corpus_class.corpus(cats)\n",
    "corpus.load(\"question_train.csv\", \"question_category_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence_filters = [filters.punctuation_filter]\n",
    "word_filters = [filters.small_word_filter, filters.stopword_filter, filters.stemming_filter]\n",
    "\n",
    "corpus.process(sentence_filters, word_filters, tr_set_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cc-based vocabulary builder, arguments {'M': 1}, \n",
      " --- vocabulary volume:  14\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.3022413402762056\n",
      " --- uniform accuracy: 0.16791983128535323\n",
      "\n",
      "cc-based vocabulary builder, arguments {'read_from_file': True, 'M': 50}, \n",
      " --- vocabulary volume:  700\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.4618519357029658\n",
      " --- uniform accuracy: 0.33589405535364725\n",
      "\n",
      "cc-based vocabulary builder, arguments {'read_from_file': True, 'M': 100}, \n",
      " --- vocabulary volume:  1400\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.4756622141725153\n",
      " --- uniform accuracy: 0.3359371184929093\n",
      "\n",
      "cc-based vocabulary builder, arguments {'read_from_file': True, 'M': 200}, \n",
      " --- vocabulary volume:  2798\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.4695494679646819\n",
      " --- uniform accuracy: 0.31050476638316943\n",
      "\n",
      "cc-based vocabulary builder, arguments {'read_from_file': True, 'M': 300}, \n",
      " --- vocabulary volume:  4064\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.4546071994566448\n",
      " --- uniform accuracy: 0.2816315676109515\n",
      "\n",
      "cc-based vocabulary builder, arguments {'read_from_file': True, 'M': 400}, \n",
      " --- vocabulary volume:  5148\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.4405705229793978\n",
      " --- uniform accuracy: 0.26264191527265823\n",
      "\n",
      "cc-based vocabulary builder, arguments {'read_from_file': True, 'M': 500}, \n",
      " --- vocabulary volume:  6197\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.4364953588408422\n",
      " --- uniform accuracy: 0.2592085616314546\n",
      "\n",
      "cc-based vocabulary builder, arguments {'read_from_file': True, 'M': 600}, \n",
      " --- vocabulary volume:  7113\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.431741000679194\n",
      " --- uniform accuracy: 0.2523142414049302\n",
      "\n",
      "cc-based vocabulary builder, arguments {'read_from_file': True, 'M': 1000}, \n",
      " --- vocabulary volume:  9709\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.42992981661761376\n",
      " --- uniform accuracy: 0.24468382684000817\n",
      "\n",
      "\n",
      " test are all finshed and saved into file!\n"
     ]
    }
   ],
   "source": [
    "args = [(\"\", {\"M\": 1})]\n",
    "for M in [50, 100, 200, 300, 400, 500, 600, 1000]:\n",
    "    args += (\"\", {\"M\": M, \"read_from_file\": True}),\n",
    "\n",
    "vocabulary_tester.test(\"cc-based\", cc_based, args, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xi-square vocabulary builder, arguments {'read_from_file': True, 'M': 2500}, \n",
      " --- vocabulary volume:  3639\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.564863029205343\n",
      " --- uniform accuracy: 0.4218203061878711\n",
      "\n",
      "xi-square vocabulary builder, arguments {'read_from_file': True, 'M': 3000}, \n",
      " --- vocabulary volume:  4304\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5605614670590899\n",
      " --- uniform accuracy: 0.4113739896434205\n",
      "\n",
      "xi-square vocabulary builder, arguments {'read_from_file': True, 'M': 4000}, \n",
      " --- vocabulary volume:  6747\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5327145121122934\n",
      " --- uniform accuracy: 0.35979062742249573\n",
      "\n",
      "xi-square vocabulary builder, arguments {'read_from_file': True, 'M': 5000}, \n",
      " --- vocabulary volume:  8204\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5114330993887254\n",
      " --- uniform accuracy: 0.3310345084102196\n",
      "\n",
      "\n",
      " test are all finshed and saved into file!\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(vocabulary_builders)\n",
    "args = []\n",
    "for M in [2500, 3000, 4000, 5000]:\n",
    "    args += (\"\", {\"M\": M, \"read_from_file\": True}),\n",
    "\n",
    "vocabulary_tester.test(\"xi-square\", vocabulary_builders.xi_square_based, args, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cc-based overall vocabulary builder, arguments {'read_from_file': True, 'M': 1}, \n",
      " --- vocabulary volume:  1\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.2626216889291374\n",
      " --- uniform accuracy: 0.12452472345484078\n",
      "\n",
      "cc-based overall vocabulary builder, arguments {'read_from_file': True, 'M': 250}, \n",
      " --- vocabulary volume:  250\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.4034412497170025\n",
      " --- uniform accuracy: 0.2792811527401758\n",
      "\n",
      "cc-based overall vocabulary builder, arguments {'read_from_file': True, 'M': 500}, \n",
      " --- vocabulary volume:  500\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.40117726964002715\n",
      " --- uniform accuracy: 0.2691361519717416\n",
      "\n",
      "\n",
      " test are all finshed and saved into file!\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(vocabulary_builders)\n",
    "args = [(\"\", {\"M\": 1, \"read_from_file\": True})]\n",
    "for M in [250, 500]:#, 750, 1000, 1250, 1500, 2000, 2500, 3000, 4000]:\n",
    "    args += (\"\", {\"M\": M, \"read_from_file\": True}),\n",
    "\n",
    "vocabulary_tester.test(\"cc-based overall\", vocabulary_builders.cc_based_overall, args, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xi-square-based overall vocabulary builder, arguments {'read_from_file': True, 'M': 1}, \n",
      " --- vocabulary volume:  1\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.2626216889291374\n",
      " --- uniform accuracy: 0.12452472345484078\n",
      "\n",
      "xi-square-based overall vocabulary builder, arguments {'read_from_file': True, 'M': 250}, \n",
      " --- vocabulary volume:  377\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5123386914195155\n",
      " --- uniform accuracy: 0.39843033557367596\n",
      "\n",
      "xi-square-based overall vocabulary builder, arguments {'read_from_file': True, 'M': 500}, \n",
      " --- vocabulary volume:  739\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5336201041430836\n",
      " --- uniform accuracy: 0.4207501493645115\n",
      "\n",
      "\n",
      " test are all finshed and saved into file!\n"
     ]
    }
   ],
   "source": [
    "args = [(\"\", {\"M\": 1,\"read_from_file\": True})]\n",
    "for M in [250, 500]:#, 750, 1000, 1250, 1500, 2000, 2500, 3000, 4000]:\n",
    "    args += (\"\", {\"M\": M, \"read_from_file\": True}),\n",
    "\n",
    "vocabulary_tester.test(\"xi-square-based overall\", vocabulary_builders.xi_square_based_overall, args, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = \"vacabulary_test_results/evaluation_all\"\n",
    "file_name += time.strftime(\"_%d-%m-%Y_%H-%M.csv\", time.gmtime())\n",
    "res_file = open(file_name, 'w+')\n",
    "res_writer = csv.writer(res_file)\n",
    "res_writer.writerow([\"vocabulary_builder\", \"comment\", \"arguments\",\n",
    "                     \"vocabulary_length\", \"tr_set_size\", \"te_set_size\", \"standard_accuracy\", \"uniform_accuracy\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xi-square vocabulary builder, arguments {'M': 1}, \n",
      " --- vocabulary volume:  1\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.2730359972832239\n",
      " --- uniform accuracy: 0.12481316713749645\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 50, 'read_from_file': True}, \n",
      " --- vocabulary volume:  71\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.4337785827484718\n",
      " --- uniform accuracy: 0.2900272582719106\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 100, 'read_from_file': True}, \n",
      " --- vocabulary volume:  144\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.4788317862802807\n",
      " --- uniform accuracy: 0.342110473280293\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 200, 'read_from_file': True}, \n",
      " --- vocabulary volume:  295\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5166402535657686\n",
      " --- uniform accuracy: 0.3918767839722415\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 300, 'read_from_file': True}, \n",
      " --- vocabulary volume:  452\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5327145121122934\n",
      " --- uniform accuracy: 0.4088423215991009\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 400, 'read_from_file': True}, \n",
      " --- vocabulary volume:  608\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.54403441249717\n",
      " --- uniform accuracy: 0.426656586373065\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 500, 'read_from_file': True}, \n",
      " --- vocabulary volume:  748\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5582974869821146\n",
      " --- uniform accuracy: 0.4402356799933854\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 600, 'read_from_file': True}, \n",
      " --- vocabulary volume:  889\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5594294770206022\n",
      " --- uniform accuracy: 0.4393819898515549\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 1000, 'read_from_file': True}, \n",
      " --- vocabulary volume:  1404\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5693909893592937\n",
      " --- uniform accuracy: 0.4428090594968383\n",
      "\n",
      "\n",
      " test are all finshed and saved into file!\n"
     ]
    }
   ],
   "source": [
    "args = [(\"\", {\"M\": 1})]\n",
    "for M in [50, 100, 200, 300, 400, 500, 600, 1000]:\n",
    "    args += (\"\", {\"M\": M, \"read_from_file\": True}),\n",
    "\n",
    "vocabulary_tester.test(\"xi-square\", xi_square_based, args, corpus, csv_file_writer=res_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xi-square vocabulary builder, arguments {'M': 1500, 'read_from_file': True}, \n",
      " --- vocabulary volume:  2116\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5745981435363369\n",
      " --- uniform accuracy: 0.43670034594487567\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 1800, 'read_from_file': True}, \n",
      " --- vocabulary volume:  2479\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5773149196287073\n",
      " --- uniform accuracy: 0.436832576775667\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 2200, 'read_from_file': True}, \n",
      " --- vocabulary volume:  3007\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.57889970568259\n",
      " --- uniform accuracy: 0.4324285745373647\n",
      "\n",
      "\n",
      " test are all finshed and saved into file!\n"
     ]
    }
   ],
   "source": [
    "args = []\n",
    "for M in [1500,1800,2200]:\n",
    "    args += (\"\", {\"M\": M, \"read_from_file\": True}),\n",
    "\n",
    "vocabulary_tester.test(\"xi-square\", xi_square_based, args, corpus, csv_file_writer=res_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ig-based vocabulary builder, arguments {'M': 1}, \n",
      " --- vocabulary volume:  9\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.32669232510753904\n",
      " --- uniform accuracy: 0.1876940472661592\n",
      "\n",
      "ig-based vocabulary builder, arguments {'M': 50, 'read_from_file': True}, \n",
      " --- vocabulary volume:  465\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5460719945664478\n",
      " --- uniform accuracy: 0.44149340171883245\n",
      "\n",
      "ig-based vocabulary builder, arguments {'M': 100, 'read_from_file': True}, \n",
      " --- vocabulary volume:  951\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5625990491283677\n",
      " --- uniform accuracy: 0.44632776436915556\n",
      "\n",
      "ig-based vocabulary builder, arguments {'M': 200, 'read_from_file': True}, \n",
      " --- vocabulary volume:  1989\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.575956531582522\n",
      " --- uniform accuracy: 0.4402253628568487\n",
      "\n",
      "ig-based vocabulary builder, arguments {'M': 300, 'read_from_file': True}, \n",
      " --- vocabulary volume:  2973\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5671270092823183\n",
      " --- uniform accuracy: 0.4153295142277682\n",
      "\n",
      "ig-based vocabulary builder, arguments {'M': 400, 'read_from_file': True}, \n",
      " --- vocabulary volume:  3942\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5399592483586144\n",
      " --- uniform accuracy: 0.36173633249845805\n",
      "\n",
      "ig-based vocabulary builder, arguments {'M': 1000, 'read_from_file': True}, \n",
      " --- vocabulary volume:  8244\n",
      " --- training classifier...\n"
     ]
    }
   ],
   "source": [
    "args = [(\"\", {\"M\": 1})]\n",
    "for M in [50, 100, 200, 300, 400, 500, 600, 1000]:\n",
    "    args += (\"\", {\"M\": M, \"read_from_file\": True}),\n",
    "\n",
    "vocabulary_tester.test(\"ig-based\", ig_based, args, corpus, csv_file_writer=res_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "args = [(\"\", {\"M\": 1, \"read_from_file\": True})]\n",
    "for M in [500, 1000, 2000, 3000, 5000, 10000]:\n",
    "    args += (\"\", {\"M\": M, \"read_from_file\": True}),\n",
    "\n",
    "vocabulary_tester.test(\"ig-based non uniform\", ig_based_non_uniform, args, corpus, csv_file_writer=res_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "args = [(\"\", {\"M\": 1})]\n",
    "for M in [50, 100, 200, 300, 400, 500, 600, 1000]:\n",
    "    args += (\"\", {\"M\": M}),\n",
    "\n",
    "vocabulary_tester.test(\"most-common\", most_common, args, corpus, csv_file_writer=res_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
