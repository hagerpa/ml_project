{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import corpus as corpus_class\n",
    "import categories, filters\n",
    "from filters import std_filters\n",
    "from sklearn.metrics import f1_score\n",
    "import pickle\n",
    "\n",
    "from transform import TrainingSupport\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", np.VisibleDeprecationWarning)\n",
    "warnings.simplefilter(\"ignore\", sklearn.metrics.classification.UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = corpus_class.load_from_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qfile_train = 'question_train.csv'\n",
    "qcatfile_train = 'question_category_train.csv'\n",
    "catfile = 'category.csv'\n",
    "qfile_test = 'question_test.csv'\n",
    "filtees = std_filters()\n",
    "\n",
    "corpus = corpus_class.corpus( categories.categories(subcategories=False) );\n",
    "corpus.load(qfile_train, qcatfile_train);\n",
    "corpus.process(corpus_size=1, test_corpus=False, **filtees);\n",
    "corpus.save();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_selection import SelectPercentile, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MNB = Pipeline(steps=[\n",
    "        ('tr_supp', TrainingSupport()),\n",
    "        ('tfidf', None),\n",
    "        ('selection', SelectPercentile(score_func=chi2)),\n",
    "        ('mnb', MultinomialNB())\n",
    "    ])\n",
    "\n",
    "ALPHA = np.logspace(-4,4,50,base=10)\n",
    "PERCENTILE = np.linspace(50,100,6)\n",
    "TFIF = []\n",
    "\n",
    "NB_PARAMS = [\n",
    "    {\n",
    "        'tfidf': [TfidfTransformer()],\n",
    "        'tfidf__use_idf': [True, False],\n",
    "        'selection__percentile': PERCENTILE,\n",
    "        'mnb__alpha': ALPHA,\n",
    "        'mnb__fit_prior': [True, False]\n",
    "    },\n",
    "    {\n",
    "        'tfidf': [None],\n",
    "        'selection__percentile': PERCENTILE,\n",
    "        'mnb__alpha': ALPHA,\n",
    "        'mnb__fit_prior': [True, False]\n",
    "    }\n",
    "]\n",
    "\n",
    "NB_CV = GridSearchCV(MNB, NB_PARAMS, scoring='f1_macro',\n",
    "                     fit_params=None, n_jobs=-1, iid=False, refit=True,\n",
    "                     cv=4, verbose=0, pre_dispatch='2*n_jobs', error_score='raise',\n",
    "                     return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NB_CV.fit(corpus.X_all, corpus.y);\n",
    "with open(\"cv_final/NB_CV\", 'wb') as file:\n",
    "    pickle.dump(NB_CV, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tr_supp', <transform.TrainingSupport at 0x7f7ffa648a20>),\n",
       " ('tfidf',\n",
       "  TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
       " ('selection', SelectPercentile(percentile=100.0,\n",
       "           score_func=<function chi2 at 0x7f7ff28f9e18>)),\n",
       " ('mnb',\n",
       "  MultinomialNB(alpha=0.18420699693267145, class_prior=None, fit_prior=False))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_CV.best_estimator_.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.585930543188\n"
     ]
    }
   ],
   "source": [
    "corpus.FREEZE_RANDOM = False\n",
    "corpus.simple_split(0.33);\n",
    "NB_CV.best_estimator_.fit(corpus.X_tr, corpus.y_tr)\n",
    "print( NB_CV.best_estimator_.score(corpus.X_te, corpus.y_te) )\n",
    "corpus.simple_split(0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LR_PARAMS = {'C': np.logspace(-4,2,50,base=10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LSVM_CV = GridSearchCV(LogisticRegression(), LR_PARAMS, scoring='f1_macro',\n",
    "                     fit_params=None, n_jobs=-1, iid=False, refit=True,\n",
    "                     cv=6, verbose=0, pre_dispatch='2*n_jobs', error_score='raise',\n",
    "                     return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LR_CV.fit(corpus.X_tr, corpus.y_tr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LR_CV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"cv_final/LR_CV\", 'wb') as file:\n",
    "    pickle.dump(LR_CV, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Supported Vector Maschines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LinearSVM = Pipeline(steps=[\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('selection', SelectPercentile(score_func=chi2)),\n",
    "        ('lsvm', LinearSVC())\n",
    "    ])\n",
    "\n",
    "PERCENTILE = np.linspace(50,100,6)\n",
    "C = np.logspace(-2,2,31,base=10)\n",
    "INTERCEPT_SCALING = np.logspace(0,3,11,base=10)\n",
    "\n",
    "LSVM_PARAMS = [\n",
    "    {\n",
    "        'selection__percentile': PERCENTILE,\n",
    "        'lsvm__C': C,\n",
    "        'lsvm__intercept_scaling': [1],\n",
    "        'lsvm__class_weight': [None]\n",
    "    },\n",
    "    {\n",
    "        'selection__percentile': PERCENTILE,\n",
    "        'lsvm__C': C,\n",
    "        'lsvm__intercept_scaling': INTERCEPT_SCALING,\n",
    "        'lsvm__class_weight': ['balanced']\n",
    "    }\n",
    "]\n",
    "\n",
    "### ZOOM ###\n",
    "C_ZOOM2 = np.logspace(-1,0,20,base=10)\n",
    "LSVM_PARAMS_ZOOM2 = [\n",
    "    {\n",
    "        'selection__percentile': [70,80,90,100],\n",
    "        'lsvm__C': C_ZOOM2,\n",
    "        'lsvm__intercept_scaling': [1],\n",
    "        'lsvm__class_weight': [None]\n",
    "    },\n",
    "    {\n",
    "        'selection__percentile': [70,80,90,100],\n",
    "        'lsvm__C': C_ZOOM2,\n",
    "        'lsvm__intercept_scaling': [25],\n",
    "        'lsvm__class_weight': ['balanced']\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LSVM_CV_ZOOM2 = GridSearchCV(LinearSVM, LSVM_PARAMS_ZOOM2, scoring='f1_macro',\n",
    "                     fit_params=None, n_jobs=-1, iid=False, refit=True,\n",
    "                     cv=3, verbose=0, pre_dispatch='2*n_jobs', error_score='raise',\n",
    "                     return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LSVM_CV_ZOOM2.fit(corpus.X_tr, corpus.y_tr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"cv_final/LSVM_CV_ZOOM2\", 'wb+') as file:\n",
    "    pickle.dump(LSVM_CV_ZOOM2, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LSVM_CV_ZOOM2.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"cv_final/LSVM_CV_ZOOM2\", 'rb') as file:\n",
    "    LSVM_CV = pickle.load(file)\n",
    "    df = pd.DataFrame( LSVM_CV.cv_results_ ).sort_values(\"mean_test_score\", ascending=False)\n",
    "with open(\"cv_final/LSVM_CV_ZOOM2.html\", \"w+\") as file:\n",
    "    file.write( df.to_html(columns=[\"mean_test_score\",\n",
    "                                    \"mean_fit_time\",\n",
    "                                    \"param_lsvm__C\",\n",
    "                                    'param_lsvm__intercept_scaling',\n",
    "                                    'param_lsvm__class_weight',\n",
    "                                    'param_selection__percentile']\n",
    "                          ) \n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus.simple_split(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lsvm = LSVM_CV.best_estimator_\n",
    "lsvm.fit(corpus.X_tr, corpus.y_tr)\n",
    "f1_score(lsvm.predict(corpus.X_te), corpus.y_te, average=\"macro\"), lsvm.score(corpus.X_te, corpus.y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = df.loc[60]['params']\n",
    "lsvm2 = LinearSVM.set_params(**params)\n",
    "lsvm2.fit(corpus.X_tr, corpus.y_tr)\n",
    "f1_score(lsvm2.predict(corpus.X_te), corpus.y_te, average=\"macro\"), lsvm2.score(corpus.X_te, corpus.y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"cv_final/NB_CV\", 'rb') as file:\n",
    "    NB_CV = pickle.load(file)\n",
    "    df = pd.DataFrame( NB_CV.cv_results_ ).sort_values(\"mean_test_score\", ascending=False)\n",
    "with open(\"cv_final/NB_HTML.html\", \"w+\") as file:\n",
    "    file.write( df.to_html(columns=[\"mean_test_score\",\n",
    "                                    \"param_mnb__alpha\",\n",
    "                                    'param_mnb__fit_prior',\n",
    "                                    'param_selection__percentile',\n",
    "                                    'param_tfidf',\n",
    "                                    'param_tfidf__use_idf'\n",
    "                                   ]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bool(123124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
