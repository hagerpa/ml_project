{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pickle\n",
    "from categories import categories\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0: question_id               1: user_id                   2: sms_guru_id               3: category_main_id         \n",
      " 4: question                  5: description               6: tags                      7: categories               \n",
      " 8: url                       9: rating_count_positive    10: rating_count_negative    11: answer_count             \n",
      "12: reported                 13: answered                 14: active                   15: deleted                  \n",
      "16: seo_locked               17: editor_locked            18: editor_id                19: created_at               \n",
      "20: updated_at               "
     ]
    }
   ],
   "source": [
    "qfile = open('question_train.csv', 'r')\n",
    "qreader = csv.reader(qfile)\n",
    "\n",
    "qfile.seek(0);\n",
    "#cols = list(zip(np.arange(21),next(reader)))\n",
    "j = 0\n",
    "for i, q in zip(np.arange(21), next(qreader)):\n",
    "    if j == 3: l = \"\\n\"; j = 0;\n",
    "    else: l = \"\"; j += 1\n",
    "        \n",
    "    print('{0:2}: {1:25}'.format(i,q), end=l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading out questions and tokenizing, checking vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cats = categories()\n",
    "\n",
    "qcatfile = open('question_category_train.csv', 'r')\n",
    "qcatreader = csv.reader(qcatfile)\n",
    "\n",
    "next(qcatreader) # skipping column discription\n",
    "\n",
    "qcat_dict = {} # mapping from question_id to the parent category_id\n",
    "catq_count = nltk.FreqDist() # maps the category_id to its\n",
    "\n",
    "for qcat in qcatreader:\n",
    "    cat_id = int(qcat[1])\n",
    "    pcat_id = cats.parent_id(cat_id)\n",
    "    q_id = int(qcat[2])\n",
    "    \n",
    "    qcat_dict[q_id] = pcat_id\n",
    "    catq_count[cats.name(cat_id)] += 1\n",
    "    \n",
    "#catq_count.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qfile = open('question_train.csv', 'r')\n",
    "qreader = csv.reader(qfile)\n",
    "\n",
    "qfile.seek(0);\n",
    "next(qreader)\n",
    "\n",
    "questions = []\n",
    "vocabulary = {}\n",
    "for cat_name in cats.all_names():\n",
    "    vocabulary[cat_name] = nltk.FreqDist()\n",
    "\n",
    "# Set this parameter to TRUE if you want to read through\n",
    "# all questions again, elsewise from file set to FALSE.\n",
    "NewRead = True \n",
    "\n",
    "if NewRead:\n",
    "    for row in qreader:\n",
    "        if len(row) == 21:\n",
    "            if int(row[0]) in qcat_dict.keys():\n",
    "                words = word_tokenize(row[4].lower())\n",
    "                cat_id = qcat_dict[int(row[0])]\n",
    "                questions += [{\"words\": words, \"cat_id\": cat_id}]\n",
    "                vocabulary[ cats.name(cat_id) ] += nltk.FreqDist(words)\n",
    "        \n",
    "    ## Saving into pickle files\n",
    "    q_file, v_file = open('questions.pkl', 'wb'), open('vocabulary.pkl', 'wb')\n",
    "    pickle.dump(questions, q_file)\n",
    "    pickle.dump(vocabulary, v_file)\n",
    "    \n",
    "else:\n",
    "    ## Loading from pickle files\n",
    "    q_file, v_file = open('questions.pkl', 'rb'), open('vocabulary.pkl', 'rb')\n",
    "    questions, vocabulary = pickle.load(q_file), pickle.load(v_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['film_and_musik', 'stars_and_promis', 'computer_and_pc', 'alltag', 'namensforschung', 'literatur_and_sprache', 'schule', 'mensch_and_koerper', 'freizeit_and_sport', 'wissen', 'liebe_and_beziehung', 'astrologie', 'games_and_spiele', 'adult']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('?', 632),\n",
       " ('die', 270),\n",
       " ('der', 246),\n",
       " ('wie', 239),\n",
       " ('von', 231),\n",
       " ('ist', 164),\n",
       " ('in', 159),\n",
       " ('wann', 144),\n",
       " ('das', 143),\n",
       " ('und', 133),\n",
       " (\"''\", 129),\n",
       " ('wer', 97),\n",
       " ('was', 94),\n",
       " ('es', 89),\n",
       " ('kommt', 80),\n",
       " ('heißt', 75),\n",
       " ('film', 74),\n",
       " ('lied', 70),\n",
       " (',', 65),\n",
       " ('den', 61),\n",
       " ('bei', 59),\n",
       " ('auf', 59),\n",
       " ('hat', 53),\n",
       " ('im', 52),\n",
       " ('.', 50),\n",
       " ('ein', 48),\n",
       " ('gibt', 48),\n",
       " ('wo', 46),\n",
       " ('dem', 45),\n",
       " ('sind', 43),\n",
       " ('ich', 40),\n",
       " ('mit', 40),\n",
       " ('aus', 38),\n",
       " ('alt', 35),\n",
       " ('wird', 35),\n",
       " ('eine', 34),\n",
       " ('album', 31),\n",
       " ('band', 30),\n",
       " ('serie', 27),\n",
       " ('für', 27),\n",
       " ('spielt', 26),\n",
       " ('neue', 26),\n",
       " ('welche', 25),\n",
       " ('oder', 25),\n",
       " ('the', 25),\n",
       " ('nächste', 24),\n",
       " ('staffel', 24),\n",
       " ('!', 22),\n",
       " ('warum', 22),\n",
       " ('raus', 22)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cats.all_names())\n",
    "vocabulary['film_and_musik'].most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'words': ['geile', 'ficken', 'titten', '!']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = {}\n",
    "example['words'] = word_tokenize(\"Geile ficken Titten!\".lower())\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = nltk.FreqDist()\n",
    "for cat_name in cats.all_names():\n",
    "    vocab += nltk.FreqDist(vocabulary[cat_name].most_common(100))\n",
    "vocab = list(vocab)\n",
    "feature_set = [(simple_features(vocab, q), cats.name(q['cat_id'])) for q in questions[:4500]]\n",
    "train_set, test_set = feature_set[:4000], feature_set[4000:4500]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('literatur_and_sprache', 'wissen')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_id = 2110\n",
    "cats.name(questions[q_id]['cat_id']), classifier.classify(simple_features(vocab, questions[q_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mein', 1) ('Name', 1) ('Tomas', 1) ('Hallo', 1) ('ist', 1)\n"
     ]
    }
   ],
   "source": [
    "test_freq = nltk.FreqDist(['Hallo', 'mein', 'name', 'ist', 'Paul'])\n",
    "test_freq2 = nltk.FreqDist(word_tokenize('Hallo mein Name ist Tomas'))\n",
    "print(*test_freq2.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'example' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-d5a9c9e6dada>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'example' is not defined"
     ]
    }
   ],
   "source": [
    "classifier.classify(simple_features(vocab,example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_features(vocab, question):\n",
    "    features = {}\n",
    "    for v in vocab:\n",
    "        features[v] = v in question['words']\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of words is 126685. \n",
      "The volume of the vocabulary is 18236.\n",
      "That makes an percentiage of 0.14\n"
     ]
    }
   ],
   "source": [
    "totNum = vocabulary.N()\n",
    "vocNum = vocabulary.B()\n",
    "print(\"\"\"The total number of words is {0}. \n",
    "The volume of the vocabulary is {1}.\n",
    "That makes an percentiage of {2:.2}\"\"\".format(totNum,vocNum,vocNum/totNum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allwordlist = [w for q in questions for w in q[1]]\n",
    "fd = nltk.FreqDist(allwordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ? x 11576   bedeutet x 1465       kommt x 947           '' x 649         oder x 506   \n",
      "       der x 4693         das x 1386          wo x 879       welche x 642         mein x 481   \n",
      "       wie x 3999         hat x 1351         wer x 810         gibt x 593          bei x 478   \n",
      "       was x 3919         von x 1260        eine x 781          den x 587         viel x 455   \n",
      "       ist x 3470         ein x 1135         mit x 769           er x 574         wenn x 452   \n",
      "       die x 2366          es x 1112        kann x 749          für x 562         welt x 430   \n",
      "       und x 2255         man x 1075       woher x 728        heißt x 554          sie x 423   \n",
      "       ich x 2011           , x 1061         auf x 701         sind x 548        haben x 415   \n",
      "        in x 1717           . x 1004       warum x 687           im x 542        viele x 415   \n",
      "      name x 1652        wann x 997           am x 683           zu x 530          aus x 380   \n"
     ]
    }
   ],
   "source": [
    "n = 50\n",
    "delta = 0\n",
    "rows = 5\n",
    "epc = int(n/rows)\n",
    "a = np.arange(n) + delta\n",
    "\n",
    "for j in range(epc):\n",
    "    row = [fd.most_common(n)[i] for i in a[j::epc]]\n",
    "    for v in row:\n",
    "        print((\"{0:>10} x {1:<6}\").format(*v),end=\"\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- anschlag            - anstecken           - antikatalytische    - antonin             - antwortetst         \n",
      "- anschliesend        - ansteckend          - antike              - antonio             - anubis              \n",
      "- anschließen         - anstellen           - antimaterie         - antony              - anunis              \n",
      "- anschlägt           - antarktis           - antipinoxe          - antreten            - anus                \n",
      "- anschrift           - anteil              - antisemetismus      - antrieb             - anwalt              \n",
      "- anschwillt          - antenne             - antisemitismus      - antrittsvorlesung   - anwendungen         \n",
      "- ansehen             - antennenverhältnis  - antje               - anträge             - anwendungsgebiete   \n",
      "- ansprechen          - anthony             - anton               - antwort             - anwesen             \n",
      "- anspruch            - antibabypille       - antonella           - antworten           - anwesend            \n",
      "- anstatt             - antidepressiva      - antonia             - antwortet           - anwort              \n"
     ]
    }
   ],
   "source": [
    "vocabArr = sorted(list(vocab))\n",
    "\n",
    "n = 50\n",
    "delta = 2000\n",
    "rows = 5\n",
    "epc = int(n/rows)\n",
    "a = np.arange(n) + delta\n",
    "\n",
    "for j in range(epc):\n",
    "    row = [vocabArr[i] for i in a[j::epc]]\n",
    "    print((\"- {:20}\"*len(row)).format(*row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Was']\n",
      "['WIEVIEL']\n",
      "['Was']\n",
      "[]\n",
      "[]\n",
      "['Wie']\n",
      "['Wie']\n",
      "['Wie']\n",
      "[]\n",
      "['Was']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "for q in questions[:10]:\n",
    "    print([w for w in q[1] if re.search('^W',w)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00001 1     1    \n",
      "00002 4     8    \n",
      "00003 9     27   \n",
      "00004 16    64   \n",
      "00005 25    125  \n",
      "00006 36    216  \n",
      "00007 49    343  \n",
      "00008 64    512  \n",
      "00009 81    729  \n",
      "00010 100   1000 \n"
     ]
    }
   ],
   "source": [
    "for x in range(1,11):\n",
    "    print(repr(x).zfill(5), repr(x**2).ljust(5),repr(x**3).ljust(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(names.words('male.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0,  3,  6,  9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48,\n",
       "        51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 81, 84, 87, 90, 93, 96, 99]),\n",
       " array([99,  2,  5,  8, 11, 14, 17, 20, 23, 26, 29, 32, 35, 38, 41, 44, 47,\n",
       "        50, 53, 56, 59, 62, 65, 68, 71, 74, 77, 80, 83, 86, 89, 92, 95, 98]),\n",
       " array([98,  1,  4,  7, 10, 13, 16, 19, 22, 25, 28, 31, 34, 37, 40, 43, 46,\n",
       "        49, 52, 55, 58, 61, 64, 67, 70, 73, 76, 79, 82, 85, 88, 91, 94, 97])]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(100)\n",
    "[b[a[::3]-i] for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('car', 'Cat'), ('house', 'Dog'), ('dor', 'Mouse')]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['car', 'house', 'dor']\n",
    "b = ['Cat', 'Dog', 'Mouse']\n",
    "list(zip(*[a,b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checking for ill-shaped lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 16070\n",
      "Number of rows with wrong length: 57:\n",
      "    fraction: 0.35 %\n"
     ]
    }
   ],
   "source": [
    "csvfile.seek(0);\n",
    "i = 0 #count total row number\n",
    "j = 0 #count false row number\n",
    "\n",
    "for row in reader:\n",
    "    i += 1\n",
    "    if(len(row) != 21):\n",
    "        #print('line size error in line {} \\n'.format(reader.line_num))\n",
    "        #print('line size is: {} \\n'.format(len(row)))\n",
    "        #print(*row)\n",
    "        #print('\\n')\n",
    "        j += 1\n",
    "\n",
    "print(\"\"\"Total number of rows: {0}\n",
    "Number of rows with wrong length: {1}:\n",
    "    fraction: {2:.2f} %\"\"\".format(i,j,(j/i)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
