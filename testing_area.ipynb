{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import corpus as corpus_class\n",
    "import categories, filters, vocabulary_builders\n",
    "from feature_extractors import multinomial_model, tfidf\n",
    "from filters import std_filters\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initializing corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qfile_train = 'question_train.csv'\n",
    "qcatfile_train = 'question_category_train.csv'\n",
    "catfile = 'category.csv'\n",
    "qfile_test = 'question_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtees = std_filters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<corpus.corpus at 0x107f75b70>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = corpus_class.corpus( categories.categories() )\n",
    "corpus.load(qfile_train, qcatfile_train)\n",
    "corpus.process(**filtees, corpus_size=-1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "spls = corpus.spell_checker\n",
    "(spls[10]).num_corrected\n",
    "for i in range(len(corpus.cats)):\n",
    "    print(len(spls[i].vocabulary), \"\\t\", spls[i].num_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 categories. \n",
      "- loaded from file: True\n",
      "\t 14417 docuemnts loaded from file. \n",
      "- processed: True\n",
      "\t sentence_filters: ['punctuation_filter'] \n",
      "\t word_filters: ['small_word_filter', 'stopword_filter', 'stemming_filter'] \n",
      "- corpus in simple split:\n",
      "\t Training-set, Test-set size: (9659, 4758) \n",
      "- made numeric features: True\n",
      "\t vocabulary_builder, M: ig_based_non_uniform, -1 \n",
      "\t feature_extractor: multinomial_model \n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus.simple_split(0.33)\n",
    "corpus.make_features(-1)\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standart Avaraging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_nb = MultinomialNB(alpha=0.1)\n",
    "clf_lr = LogisticRegression(C=3.0)\n",
    "clf_svc = SVC(C=1.0, probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bcf = VotingClassifier(estimators=[('lr', clf_lr), ('nb', clf_nb), ('svc', clf_svc)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bcf.fit(corpus.X_tr, corpus.y_tr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61174755259320979"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcf.score(corpus.X_te, corpus.y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Classfier for avaraging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3258533570"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.cv_split(3)\n",
    "SEED = corpus.random_seed\n",
    "SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "P = []\n",
    "lP = []\n",
    "corpus.reset()\n",
    "for corpus in corpus:\n",
    "    corpus.make_features()\n",
    "    \n",
    "    clf_nb = MultinomialNB(alpha=0.1)\n",
    "    clf_nb.fit(corpus.X_tr, corpus.y_tr)\n",
    "    clf_lr = LogisticRegression(C=2.0)\n",
    "    clf_lr.fit(corpus.X_tr, corpus.y_tr)\n",
    "    clf_svc = SVC(C=1.0, probability=True)\n",
    "    clf_svc.fit(corpus.X_tr, corpus.y_tr)\n",
    "    \n",
    "    A = clf_nb.predict_proba( corpus.X_te )\n",
    "    B = clf_lr.predict_proba( corpus.X_te )\n",
    "    C = clf_svc.predict_proba( corpus.X_te )\n",
    "    \n",
    "    P += [ np.concatenate((A, B, C), axis=1) ]\n",
    "    lP += [ corpus.y_te ]\n",
    "    \n",
    "Xp_tr = np.concatenate((P[0], P[1]), axis=0)\n",
    "yp_tr = np.concatenate((lP[0], lP[1]), axis=0)\n",
    "\n",
    "Xp_te = P[2]\n",
    "yp_te = lP[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61508019162674443"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_fin = RandomForestClassifier(n_estimators=100, max_features=3)\n",
    "#clf_fin = LogisticRegression(C=1.0)\n",
    "clf_fin.fit(Xp_tr, yp_tr)\n",
    "clf_fin.score(Xp_te, yp_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 categories. \n",
      "- loaded from file: True\n",
      "\t 14417 docuemnts loaded from file. \n",
      "- processed: True\n",
      "\t sentence_filters: ['punctuation_filter'] \n",
      "\t word_filters: ['small_word_filter', 'stopword_filter', 'stemming_filter'] \n",
      "- corpus in cv-split:\n",
      "\t fold 3 / 3 \n",
      "\t Training-set, Test-set size: (9616, 4801) \n",
      "- made numeric features: True\n",
      "\t vocabulary_builder, M: ig_based_non_uniform, -1 \n",
      "\t feature_extractor: multinomial_model \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pydoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module corpus:\n",
      "\n",
      "NAME\n",
      "    corpus\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        corpus\n",
      "    \n",
      "    class corpus(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, categories)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __next__(self)\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  cv_split(self, n_folds, random_seed=None)\n",
      "     |      This mehtod provides an efficient way to creat n_folds on the corpus for cross validation.\n",
      "     |      It Counts term_frequencies for each folds seperatly so that they can simply be merged. After\n",
      "     |      running this method, the corpus becomes an iterable object, which for each iteration creats a new\n",
      "     |      traing-/ test-set split.\n",
      "     |  \n",
      "     |  load(self, filename_questions, filename_categories)\n",
      "     |  \n",
      "     |  make_features(self, M=-1, vocabulary_builder=<function ig_based_non_uniform at 0x1052d8d08>, feature_extractor=<function multinomial_model at 0x1052cf378>)\n",
      "     |      Creats sparse (csr) feature matricies for the training- and test-set applying the \n",
      "     |      given feature models for feature selcetion and extraction.\n",
      "     |  \n",
      "     |  process(self, sentence_filters=None, word_filters=None, corpus_size=-1)\n",
      "     |      This method runs given filters on the raw set of documents. One can choose a stratified\n",
      "     |      subset of the documents by specifying corpus_size, note however that this set size can not\n",
      "     |      simply be extended. One needs to reload the corpus.\n",
      "     |  \n",
      "     |  process_example(self, raw_documents)\n",
      "     |      Pass this method an iterable of documents (strings) and it will process the docuemnts\n",
      "     |      acordingly to the training set. It will return a sparse (csr) feature matrx.\n",
      "     |  \n",
      "     |  reset(self)\n",
      "     |  \n",
      "     |  save(self)\n",
      "     |  \n",
      "     |  simple_split(self, test_size=0, random_seed=None)\n",
      "     |  \n",
      "     |  size(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    count_freqs(documents, lables, n_cats)\n",
      "    \n",
      "    load_from_file()\n",
      "    \n",
      "    make_freq_vec(frequencies, terms, n_cats)\n",
      "\n",
      "FILE\n",
      "    /Users/paulhager/Dropbox/studium16-17/ml_project/corpus.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pydoc.help(corpus_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
