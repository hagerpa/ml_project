{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv, re, pickle, itertools, progressbar, importlib\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import time\n",
    "\n",
    "import categories\n",
    "import corpus as corpus_class\n",
    "import filters, vocabulary_builders, vocabulary_tester\n",
    "from vocabulary_builders import most_common, most_common_reduced, ig_based, ig_based_non_uniform, xi_square_based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cats = categories.categories()\n",
    "corpus = corpus_class.corpus(cats)\n",
    "corpus.load(\"question_train.csv\", \"question_category_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence_filters = [filters.punctuation_filter]\n",
    "word_filters = [filters.small_word_filter, filters.stopword_filter, filters.stemming_filter]\n",
    "\n",
    "corpus.process(sentence_filters, word_filters, tr_set_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = \"vacabulary_test_results/evaluation_all\"\n",
    "file_name += time.strftime(\"_%d-%m-%Y_%H-%M.csv\", time.gmtime())\n",
    "res_file = open(file_name, 'w+')\n",
    "res_writer = csv.writer(res_file)\n",
    "res_writer.writerow([\"vocabulary_builder\", \"comment\", \"arguments\",\n",
    "                     \"vocabulary_length\", \"tr_set_size\", \"te_set_size\", \"standard_accuracy\", \"uniform_accuracy\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xi-square vocabulary builder, arguments {'M': 1}, \n",
      " --- vocabulary volume:  1\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.2730359972832239\n",
      " --- uniform accuracy: 0.12481316713749645\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 50, 'read_from_file': True}, \n",
      " --- vocabulary volume:  71\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.4337785827484718\n",
      " --- uniform accuracy: 0.2900272582719106\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 100, 'read_from_file': True}, \n",
      " --- vocabulary volume:  144\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.4788317862802807\n",
      " --- uniform accuracy: 0.342110473280293\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 200, 'read_from_file': True}, \n",
      " --- vocabulary volume:  295\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5166402535657686\n",
      " --- uniform accuracy: 0.3918767839722415\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 300, 'read_from_file': True}, \n",
      " --- vocabulary volume:  452\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5327145121122934\n",
      " --- uniform accuracy: 0.4088423215991009\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 400, 'read_from_file': True}, \n",
      " --- vocabulary volume:  608\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.54403441249717\n",
      " --- uniform accuracy: 0.426656586373065\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 500, 'read_from_file': True}, \n",
      " --- vocabulary volume:  748\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5582974869821146\n",
      " --- uniform accuracy: 0.4402356799933854\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 600, 'read_from_file': True}, \n",
      " --- vocabulary volume:  889\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5594294770206022\n",
      " --- uniform accuracy: 0.4393819898515549\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 1000, 'read_from_file': True}, \n",
      " --- vocabulary volume:  1404\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5693909893592937\n",
      " --- uniform accuracy: 0.4428090594968383\n",
      "\n",
      "\n",
      " test are all finshed and saved into file!\n"
     ]
    }
   ],
   "source": [
    "args = [(\"\", {\"M\": 1})]\n",
    "for M in [50, 100, 200, 300, 400, 500, 600, 1000]:\n",
    "    args += (\"\", {\"M\": M, \"read_from_file\": True}),\n",
    "\n",
    "vocabulary_tester.test(\"xi-square\", xi_square_based, args, corpus, csv_file_writer=res_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xi-square vocabulary builder, arguments {'M': 1500, 'read_from_file': True}, \n",
      " --- vocabulary volume:  2116\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5745981435363369\n",
      " --- uniform accuracy: 0.43670034594487567\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 1800, 'read_from_file': True}, \n",
      " --- vocabulary volume:  2479\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5773149196287073\n",
      " --- uniform accuracy: 0.436832576775667\n",
      "\n",
      "xi-square vocabulary builder, arguments {'M': 2200, 'read_from_file': True}, \n",
      " --- vocabulary volume:  3007\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.57889970568259\n",
      " --- uniform accuracy: 0.4324285745373647\n",
      "\n",
      "\n",
      " test are all finshed and saved into file!\n"
     ]
    }
   ],
   "source": [
    "args = []\n",
    "for M in [1500,1800,2200]:\n",
    "    args += (\"\", {\"M\": M, \"read_from_file\": True}),\n",
    "\n",
    "vocabulary_tester.test(\"xi-square\", xi_square_based, args, corpus, csv_file_writer=res_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ig-based vocabulary builder, arguments {'M': 1}, \n",
      " --- vocabulary volume:  9\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.32669232510753904\n",
      " --- uniform accuracy: 0.1876940472661592\n",
      "\n",
      "ig-based vocabulary builder, arguments {'M': 50, 'read_from_file': True}, \n",
      " --- vocabulary volume:  465\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5460719945664478\n",
      " --- uniform accuracy: 0.44149340171883245\n",
      "\n",
      "ig-based vocabulary builder, arguments {'M': 100, 'read_from_file': True}, \n",
      " --- vocabulary volume:  951\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5625990491283677\n",
      " --- uniform accuracy: 0.44632776436915556\n",
      "\n",
      "ig-based vocabulary builder, arguments {'M': 200, 'read_from_file': True}, \n",
      " --- vocabulary volume:  1989\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.575956531582522\n",
      " --- uniform accuracy: 0.4402253628568487\n",
      "\n",
      "ig-based vocabulary builder, arguments {'M': 300, 'read_from_file': True}, \n",
      " --- vocabulary volume:  2973\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5671270092823183\n",
      " --- uniform accuracy: 0.4153295142277682\n",
      "\n",
      "ig-based vocabulary builder, arguments {'M': 400, 'read_from_file': True}, \n",
      " --- vocabulary volume:  3942\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.5399592483586144\n",
      " --- uniform accuracy: 0.36173633249845805\n",
      "\n",
      "ig-based vocabulary builder, arguments {'M': 1000, 'read_from_file': True}, \n",
      " --- vocabulary volume:  8244\n",
      " --- training classifier...\n"
     ]
    }
   ],
   "source": [
    "args = [(\"\", {\"M\": 1})]\n",
    "for M in [50, 100, 200, 300, 400, 500, 600, 1000]:\n",
    "    args += (\"\", {\"M\": M, \"read_from_file\": True}),\n",
    "\n",
    "vocabulary_tester.test(\"ig-based\", ig_based, args, corpus, csv_file_writer=res_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "args = [(\"\", {\"M\": 1, \"read_from_file\": True})]\n",
    "for M in [500, 1000, 2000, 3000, 5000, 10000]:\n",
    "    args += (\"\", {\"M\": M, \"read_from_file\": True}),\n",
    "\n",
    "vocabulary_tester.test(\"ig-based non uniform\", ig_based_non_uniform, args, corpus, csv_file_writer=res_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "args = [(\"\", {\"M\": 1})]\n",
    "for M in [50, 100, 200, 300, 400, 500, 600, 1000]:\n",
    "    args += (\"\", {\"M\": M}),\n",
    "\n",
    "vocabulary_tester.test(\"most-common\", most_common, args, corpus, csv_file_writer=res_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
