{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv, re, pickle, itertools, progressbar, importlib\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import time\n",
    "\n",
    "import categories\n",
    "import corpus as corpus_class\n",
    "import filters, vocabulary_builders, vocabulary_tester\n",
    "from vocabulary_builders import most_common, most_common_reduced, ig_based, ig_based_non_uniform, xi_square_based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cats = categories.categories()\n",
    "corpus = corpus_class.corpus(cats)\n",
    "corpus.load(\"question_train.csv\", \"question_category_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence_filters = [filters.punctuation_filter]\n",
    "word_filters = [filters.small_word_filter, filters.stopword_filter, filters.stemming_filter]\n",
    "\n",
    "corpus.process(sentence_filters, word_filters, tr_set_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = \"vacabulary_test_results/evaluation_all\"\n",
    "file_name += time.strftime(\"_%d-%m-%Y_%H-%M.csv\", time.gmtime())\n",
    "res_file = open(file_name, 'w+')\n",
    "res_writer = csv.writer(res_file)\n",
    "res_writer.writerow([\"vocabulary_builder\", \"comment\", \"arguments\",\n",
    "                     \"vocabulary_length\", \"tr_set_size\", \"te_set_size\", \"standard_accuracy\", \"uniform_accuracy\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xi-square vocabulary builder, arguments {'M': 200}, small test\n",
      " --- vocabulary volume:  280\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.4\n",
      " --- uniform accuracy: 0.3216646915176327\n",
      "\n",
      "xi-square vocabulary builder, arguments {'read_from_file': True, 'M': 300}, small test\n",
      " --- vocabulary volume:  448\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.41\n",
      " --- uniform accuracy: 0.3509507649213532\n",
      "\n",
      "xi-square vocabulary builder, arguments {'read_from_file': True, 'M': 400}, small test\n",
      " --- vocabulary volume:  554\n",
      " --- training classifier...\n",
      " --- ...classifier is trained.\n",
      " --- testing classifier: \n",
      " --- standart accurcy: 0.4\n",
      " --- uniform accuracy: 0.3231729871435754\n",
      "\n",
      "\n",
      " test are all finshed and saved into file!\n"
     ]
    }
   ],
   "source": [
    "args = [(\"\", {\"M\": 1})]\n",
    "for M in [50, 100, 200, 300, 400, 500, 600, 1000]:\n",
    "    args += (\"\", {\"M\": M, \"read_from_file\": True}),\n",
    "\n",
    "vocabulary_tester.test(\"xi-square\", xi_square_based, args, corpus, csv_file_writer=res_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "args = [(\"\", {\"M\": 1})]\n",
    "for M in [50, 100, 200, 300, 400, 500, 600, 1000]:\n",
    "    args += (\"\", {\"M\": M, \"read_from_file\": True}),\n",
    "\n",
    "vocabulary_tester.test(\"ig-based\", ig_based, args, corpus, csv_file_writer=res_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "args = [(\"\", {\"M\": 1})]\n",
    "for M in [500, 1000, 2000, 3000, 5000, 10000]:\n",
    "    args += (\"\", {\"M\": M, \"read_from_file\": True}),\n",
    "\n",
    "vocabulary_tester.test(\"ig-based non uniform\", ig_based_non_uniform, args, corpus, csv_file_writer=res_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "args = [(\"\", {\"M\": 1})]\n",
    "for M in [50, 100, 200, 300, 400, 500, 600, 1000]:\n",
    "    args += (\"\", {\"M\": M}),\n",
    "\n",
    "vocabulary_tester.test(\"most-common\", most_common, args, corpus, csv_file_writer=res_writer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
